In this repositiory, I have implemented 5 different mini-projects related to different subjects and methods in an Information Retrieval System.


### Inverted Index, Positional Index, Boolean Queries, and Proximity Queries

- **Objective:** Implement search engine components for documents, including inverted and positional indexes, to handle Boolean and proximity queries.
- **Approach:** 
  - Developed an inverted index for efficient term-based searching.
  - Created a positional index to support phrase and proximity queries.
  - Implemented Boolean queries using logical operators (AND, OR, NOT) and proximity queries for searching within specific word distances.

### Spelling Correction and Wildcard Queries

- **Objective:** Enhance search engine functionality with spelling correction and support for wildcard queries.
- **Approach:** 
  - Implemented a spelling correction algorithm using techniques like edit distance to suggest correct spellings.
  - Developed a system for handling wildcard queries, allowing flexible search patterns by expanding terms with wildcards.

### Index Block Merging, Gamma Coding, and Bit Manipulation

- **Objective:** Optimize indexing and storage through advanced techniques.
- **Approach:** 
  - Implemented index block merging to efficiently combine index segments.
  - Applied gamma coding for compressing index data, reducing storage requirements.
  - Utilized bit manipulation techniques to further optimize the index storage and retrieval process.

### Document Ranking using Space Vector, Probabilistic, and Language Models

- **Objective:** Implement and compare different document ranking models in an information retrieval system.
- **Approach:** 
  - Developed document ranking algorithms based on the Vector Space Model, Probabilistic Model, and Language Model.
  - Compared the effectiveness of these models in retrieving relevant documents, considering factors like term frequency, inverse document frequency, and probabilistic relevance.

### Naive Bayes Classification, Word Embedding, SVM, and LSA

- **Objective:** Explore various text classification and representation techniques.
- **Approach:** 
  - Implemented Naive Bayes for simple yet effective text classification.
  - Used Word Embeddings (Word2Vec) for capturing semantic meaning in texts.
  - Applied Support Vector Machines (SVM) for more complex classification tasks.
  - Explored Latent Semantic Analysis (LSA) to uncover hidden relationships in text data.

---
